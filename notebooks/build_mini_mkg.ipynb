{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Mini Materials Knowledge Graph — Common Semiconductors\n",
        "**What I'm building:** a tiny pipeline that turns a small semiconductors table into **RDF triples**, then I query it using **SPARQL**. I keep the ontology minimal and readable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## Some basic terminologies\n",
        "- **Ontology** → my small schema + vocabulary for this domain (classes + relations).\n",
        "- **RDF triple** → one fact written as `subject — predicate — object`.\n",
        "- **Namespace** → URL prefix so my identifiers are unique.\n",
        "- **SPARQL** → my query tool for RDF graphs (like SQL but for triples).\n",
        "- **Turtle (.ttl)** → compact text format to store RDF.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bfbaab76",
      "metadata": {},
      "source": [
        "**Imports**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "d4065d28",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OK\n"
          ]
        }
      ],
      "source": [
        "import os; print(\"OK\" if os.getenv(\"OPENAI_API_KEY\") else \"MISSING\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from rdflib import Graph, Namespace, URIRef, Literal\n",
        "from rdflib.namespace import RDF, RDFS, XSD\n",
        "from pathlib import Path\n",
        "import re\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "093431dc",
      "metadata": {},
      "source": [
        "## 1) Setup\n",
        "read a tiny CSV and map it into RDF using `rdflib`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "0c77e382",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using data: E:\\Projects\\Semantic_models_for-MSE\\data\\semiconductors_small.csv\n"
          ]
        }
      ],
      "source": [
        "DATA = Path(\"../data/semiconductors_small.csv\")   # CSV lives in the repo\n",
        "TTL_OUT = Path(\"../data/semiconductors_small.ttl\")# RDF Turtle output\n",
        "print(\"Using data:\", DATA.resolve())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## 2) Ontology skeleton (small and pragmatic)\n",
        "a few classes and properties that I actually need for the initial CSV i am using.  \n",
        "Classes: `Material`, `SynthesisMethod`, `CrystalStructure`, `Property`  \n",
        "Properties:  \n",
        "- data: `hasBandGap` (float eV), `hasLatticeConstant` (float Å)  \n",
        "- object: `hasCrystalStructure`, `synthesizedBy`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ontology initialized. Triples so far: 16\n"
          ]
        }
      ],
      "source": [
        "g = Graph()\n",
        "\n",
        "# Namespace for my identifiers (can switch to a real domain later)\n",
        "EX = Namespace(\"http://example.org/mse#\")\n",
        "g.bind(\"ex\", EX)\n",
        "g.bind(\"rdfs\", RDFS)\n",
        "g.bind(\"xsd\", XSD)\n",
        "\n",
        "# Classes\n",
        "Material         = EX.Material\n",
        "SynthesisMethod  = EX.SynthesisMethod\n",
        "CrystalStructure = EX.CrystalStructure\n",
        "Property         = EX.Property\n",
        "\n",
        "for cls in [Material, SynthesisMethod, CrystalStructure, Property]:\n",
        "    g.add((cls, RDF.type, RDFS.Class))\n",
        "\n",
        "# Properties\n",
        "hasBandGap          = EX.hasBandGap\n",
        "hasLatticeConstant  = EX.hasLatticeConstant\n",
        "hasCrystalStructure = EX.hasCrystalStructure\n",
        "synthesizedBy       = EX.synthesizedBy\n",
        "\n",
        "for prop in [hasBandGap, hasLatticeConstant, hasCrystalStructure, synthesizedBy]:\n",
        "    g.add((prop, RDF.type, RDF.Property))\n",
        "\n",
        "# Light domain/range annotations (sanity helpers for later validation)\n",
        "g.add((hasBandGap, RDFS.domain, Material));         g.add((hasBandGap, RDFS.range, XSD.float))\n",
        "g.add((hasLatticeConstant, RDFS.domain, Material)); g.add((hasLatticeConstant, RDFS.range, XSD.float))\n",
        "g.add((hasCrystalStructure, RDFS.domain, Material));g.add((hasCrystalStructure, RDFS.range, CrystalStructure))\n",
        "g.add((synthesizedBy, RDFS.domain, Material));      g.add((synthesizedBy, RDFS.range, SynthesisMethod))\n",
        "\n",
        "print(\"Ontology initialized. Triples so far:\", len(g))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Load CSV and mint entities  \n",
        "create IRIs (Internationalized Resource Identifier) from labels (simple normalization) and assert triples for each row."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "After ingest: triples = 76\n"
          ]
        }
      ],
      "source": [
        "# --- 1) Read CSV with correct dtypes ---\n",
        "# Only force the TEXT columns to string dtype. Let numeric columns be inferred as float.\n",
        "STRING_COLS = [\"material\", \"crystal_structure\", \"typical_synthesis\"]\n",
        "df = pd.read_csv(DATA, dtype={col: \"string\" for col in STRING_COLS})\n",
        "\n",
        "# Ensure numeric columns are numeric (coerce bad cells to NaN gracefully)\n",
        "df[\"band_gap_eV\"] = pd.to_numeric(df.get(\"band_gap_eV\"), errors=\"coerce\")\n",
        "df[\"lattice_const_A\"] = pd.to_numeric(df.get(\"lattice_const_A\"), errors=\"coerce\")\n",
        "\n",
        "# --- 2) Helpers ---\n",
        "def _slugify(text: str) -> str:\n",
        "    # normalize to an IRI-safe slug\n",
        "    text = text.strip().replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\").replace(\"/\", \"_\")\n",
        "    text = re.sub(r\"[^A-Za-z0-9_]\", \"_\", text)\n",
        "    return text\n",
        "\n",
        "def mint_entity(label, cls: URIRef, fallback_prefix: str, idx: int):\n",
        "    \"\"\"\n",
        "    label may be pandas NA/None/float NaN or a proper string.\n",
        "    If missing, mint a stable fallback IRI like ex:Material_42 and add a descriptive rdfs:label.\n",
        "    \"\"\"\n",
        "    if label is None or pd.isna(label):\n",
        "        safe = f\"{fallback_prefix}_{idx}\"\n",
        "        iri = EX[safe]\n",
        "        g.add((iri, RDF.type, cls))\n",
        "        g.add((iri, RDFS.label, Literal(f\"{fallback_prefix} #{idx}\")))\n",
        "        return iri\n",
        "\n",
        "    label_str = str(label)\n",
        "    safe = _slugify(label_str)\n",
        "    iri = EX[safe]\n",
        "    g.add((iri, RDF.type, cls))\n",
        "    g.add((iri, RDFS.label, Literal(label_str)))\n",
        "    return iri\n",
        "\n",
        "# --- 3) Ingest rows ---\n",
        "for i, row in df.iterrows():\n",
        "    mat = mint_entity(row.get(\"material\"),          Material,         \"Material\",         i)\n",
        "    cs  = mint_entity(row.get(\"crystal_structure\"), CrystalStructure, \"CrystalStructure\", i)\n",
        "    sm  = mint_entity(row.get(\"typical_synthesis\"), SynthesisMethod,  \"SynthesisMethod\",  i)\n",
        "\n",
        "    # Data properties (numbers): add if present\n",
        "    if pd.notna(row.get(\"band_gap_eV\")):\n",
        "        g.add((mat, hasBandGap, Literal(float(row[\"band_gap_eV\"]), datatype=XSD.float)))\n",
        "    if pd.notna(row.get(\"lattice_const_A\")):\n",
        "        g.add((mat, hasLatticeConstant, Literal(float(row[\"lattice_const_A\"]), datatype=XSD.float)))\n",
        "\n",
        "    # Object properties (links)\n",
        "    g.add((mat, hasCrystalStructure, cs))\n",
        "    g.add((mat, synthesizedBy, sm))\n",
        "\n",
        "print(\"After ingest: triples =\", len(g))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Serialize to Turtle\n",
        "write the RDF graph to a `.ttl` file so it’s versionable in Git and easy to inspect.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wrote: E:\\Projects\\Semantic_models_for-MSE\\data\\semiconductors_small.ttl\n"
          ]
        }
      ],
      "source": [
        "ttl_bytes = g.serialize(format=\"turtle\", encoding=\"utf-8\")  # returns bytes when encoding is set, else str\n",
        "TTL_OUT.write_bytes(ttl_bytes)\n",
        "print(\"Wrote:\", TTL_OUT.resolve())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## 5) SPARQL queries (quick checks)\n",
        "query the in‑memory graph via `rdflib` to verify the ontology + data mapping.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(rdflib.term.Literal('Gallium Nitride'), rdflib.term.Literal('3.4', datatype=rdflib.term.URIRef('http://www.w3.org/2001/XMLSchema#float')))\n",
            "(rdflib.term.Literal('Silicon Carbide (4H)'), rdflib.term.Literal('3.26', datatype=rdflib.term.URIRef('http://www.w3.org/2001/XMLSchema#float')))\n",
            "(rdflib.term.Literal('Gallium Arsenide'), rdflib.term.Literal('1.42', datatype=rdflib.term.URIRef('http://www.w3.org/2001/XMLSchema#float')))\n",
            "(rdflib.term.Literal('Indium Phosphide'), rdflib.term.Literal('1.34', datatype=rdflib.term.URIRef('http://www.w3.org/2001/XMLSchema#float')))\n",
            "(rdflib.term.Literal('Silicon'), rdflib.term.Literal('1.12', datatype=rdflib.term.URIRef('http://www.w3.org/2001/XMLSchema#float')))\n"
          ]
        }
      ],
      "source": [
        "# Q1) Materials with band gap > 1 eV (descending)\n",
        "q1 = \"\"\"PREFIX ex: <http://example.org/mse#>\n",
        "SELECT ?material ?Eg\n",
        "WHERE {\n",
        "  ?m a ex:Material ;\n",
        "     rdfs:label ?material ;\n",
        "     ex:hasBandGap ?Eg .\n",
        "  FILTER(?Eg > 1.0)\n",
        "}\n",
        "ORDER BY DESC(?Eg)\n",
        "\"\"\"\n",
        "for row in g.query(q1, initNs={\"rdfs\": RDFS}):\n",
        "    print(row)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(rdflib.term.Literal('Indium Phosphide'),)\n",
            "(rdflib.term.Literal('Gallium Nitride'),)\n"
          ]
        }
      ],
      "source": [
        "# Q2) Materials synthesized by MOCVD\n",
        "q2 = \"\"\"PREFIX ex: <http://example.org/mse#>\n",
        "SELECT ?material\n",
        "WHERE {\n",
        "  ?m a ex:Material ;\n",
        "     rdfs:label ?material ;\n",
        "     ex:synthesizedBy ?meth .\n",
        "  ?meth rdfs:label \"MOCVD\" .\n",
        "}\n",
        "\"\"\"\n",
        "for row in g.query(q2, initNs={\"rdfs\": RDFS}):\n",
        "    print(row)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(rdflib.term.Literal('Silicon'),)\n",
            "(rdflib.term.Literal('Germanium'),)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Q3) Materials with diamond cubic structure\n",
        "q3 = \"\"\"PREFIX ex: <http://example.org/mse#>\n",
        "SELECT ?material\n",
        "WHERE {\n",
        "  ?m a ex:Material ;\n",
        "     rdfs:label ?material ;\n",
        "     ex:hasCrystalStructure ?cs .\n",
        "  ?cs rdfs:label \"Diamond cubic\" .\n",
        "}\n",
        "\"\"\"\n",
        "for row in g.query(q3, initNs={\"rdfs\": RDFS}):\n",
        "    print(row)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) Creating safeguard for possible problems in data scrapping!!\n",
        "keep a few small rules here to catch obvious issues (labels missing, negative band gaps, etc.)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No obvious problems ✅\n"
          ]
        }
      ],
      "source": [
        "problems = []\n",
        "\n",
        "# A) All Materials should have labels\n",
        "for s in g.subjects(RDF.type, EX.Material):\n",
        "    if (s, RDFS.label, None) not in g:\n",
        "        problems.append(f\"Material without label: {s}\")\n",
        "\n",
        "# B) Band gap must be numeric and non-negative\n",
        "for s,p,o in g.triples((None, EX.hasBandGap, None)):\n",
        "    try:\n",
        "        if float(o) < 0:\n",
        "            problems.append(f\"Negative band gap for {s}\")\n",
        "    except Exception:\n",
        "        problems.append(f\"Non-numeric band gap for {s}: {o}\")\n",
        "\n",
        "print(\"No obvious problems ✅\" if not problems else \"Consistency problems:\")\n",
        "for x in problems:\n",
        "    print(\"-\", x)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## 7) Placeholder for LLM‑assisted extraction\n",
        "When I replace this stub with a real LLM/NLP call, I’ll feed abstracts/tables and get back candidate triples to add to the graph.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Triples after stub insert: 77\n"
          ]
        }
      ],
      "source": [
        "def propose_triples_from_text(text: str):\n",
        "    # demo placeholder: pretend I parsed that GaN has Eg ~3.4 eV\n",
        "    return [(EX.GaN, EX.hasBandGap, Literal(3.4, datatype=XSD.float))]\n",
        "\n",
        "for s,p,o in propose_triples_from_text(\"GaN has band gap ~3.4 eV\"):\n",
        "    g.add((s,p,o))\n",
        "\n",
        "print(\"Triples after stub insert:\", len(g))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## 8) Save again after updates\n",
        "I keep the TTL in sync with the in‑memory graph.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Updated: E:\\Projects\\Semantic_models_for-MSE\\data\\semiconductors_small.ttl\n"
          ]
        }
      ],
      "source": [
        "TTL_OUT.write_bytes(g.serialize(format=\"turtle\", encoding=\"utf-8\"))\n",
        "print(\"Updated:\", TTL_OUT.resolve())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "5ced5f92",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "kg.html\n",
            "Wrote: kg.html (open this file in your browser)\n"
          ]
        }
      ],
      "source": [
        "from pyvis.network import Network\n",
        "from rdflib import Graph, URIRef, BNode, Literal\n",
        "\n",
        "\n",
        "def display_label(term):\n",
        "    \"\"\"Human label for a node/edge: prefer rdfs:label, then QName, then short str.\"\"\"\n",
        "    lab = g.value(term, RDFS.label)\n",
        "    if lab:\n",
        "        return str(lab).strip()\n",
        "    # QName only for URIRefs\n",
        "    if isinstance(term, URIRef):\n",
        "        try:\n",
        "            return g.namespace_manager.normalizeUri(term)\n",
        "        except Exception:\n",
        "            pass\n",
        "    s = str(term).strip()\n",
        "    return s\n",
        "\n",
        "def node_id(term):\n",
        "    \"\"\"Stable ID for pyvis (avoid raw labels).\"\"\"\n",
        "    # Use actual URI for URIRefs/BNodes; fallback to hash\n",
        "    if isinstance(term, (URIRef, BNode)):\n",
        "        return str(term)\n",
        "    return f\"lit:{hash((str(term), type(term).__name__))}\"\n",
        "\n",
        "def node_style(term):\n",
        "    \"\"\"Color by class where possible (Material / CrystalStructure / SynthesisMethod).\"\"\"\n",
        "    # Try to infer from rdf:type (lightweight check)\n",
        "    types = set(g.objects(term, RDF.type)) if isinstance(term, (URIRef, BNode)) else set()\n",
        "    # Resolve EX namespace if present\n",
        "    ns = dict(g.namespace_manager.namespaces())\n",
        "    EX = ns.get(\"ex\")\n",
        "    def is_type(tname):\n",
        "        return any(str(t).endswith(f\"#{tname}\") or str(t).endswith(f\"/{tname}\") for t in types)\n",
        "    if is_type(\"Material\"):\n",
        "        return dict(color=\"#2b8a3e\", shape=\"ellipse\")\n",
        "    if is_type(\"CrystalStructure\"):\n",
        "        return dict(color=\"#1c7ed6\", shape=\"ellipse\")\n",
        "    if is_type(\"SynthesisMethod\"):\n",
        "        return dict(color=\"#e8590c\", shape=\"ellipse\")\n",
        "    if isinstance(term, Literal):\n",
        "        return dict(color=\"#bfbfbf\", shape=\"box\")\n",
        "    return dict(color=\"#666666\", shape=\"ellipse\")\n",
        "\n",
        "def visualize_graph_pyvis(g, max_edges=1500, show_literals=False, height=\"700px\"):\n",
        "    net = Network(height=height, width=\"100%\", directed=True, notebook=True,\n",
        "                  cdn_resources=\"in_line\")  # avoid the Jupyter warning\n",
        "    net.toggle_physics(True)\n",
        "\n",
        "    added = set()\n",
        "    edge_count = 0\n",
        "\n",
        "    for s, p, o in g.triples((None, None, None)):\n",
        "        if edge_count >= max_edges:\n",
        "            break\n",
        "\n",
        "        # skip literal nodes unless asked\n",
        "        if not show_literals and isinstance(o, Literal):\n",
        "            # still add edge to a small boxed literal if you like:\n",
        "            # continue\n",
        "            pass\n",
        "\n",
        "        sid = node_id(s); so = node_id(o)\n",
        "        if sid not in added:\n",
        "            net.add_node(sid, label=display_label(s), **node_style(s))\n",
        "            added.add(sid)\n",
        "        if show_literals or not isinstance(o, Literal):\n",
        "            if so not in added:\n",
        "                net.add_node(so, label=display_label(o), **node_style(o))\n",
        "                added.add(so)\n",
        "\n",
        "        net.add_edge(sid, so, label=display_label(p))\n",
        "        edge_count += 1\n",
        "\n",
        "    net.show(\"kg.html\")\n",
        "    print(\"Wrote: kg.html (open this file in your browser)\")\n",
        "\n",
        "visualize_graph_pyvis(g, max_edges=1000, show_literals=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11b3bd6e",
      "metadata": {},
      "source": [
        "# Utilizing LLM (Chat GPT) for parsing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56c4fd2c",
      "metadata": {},
      "source": [
        "*Quick smoke test*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "3bed8981",
      "metadata": {},
      "outputs": [
        {
          "ename": "RateLimitError",
          "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mRateLimitError\u001b[39m                            Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m os.getenv(\u001b[33m\"\u001b[39m\u001b[33mOPENAI_API_KEY\u001b[39m\u001b[33m\"\u001b[39m), \u001b[33m\"\u001b[39m\u001b[33mAPI key missing\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      5\u001b[39m client = OpenAI()\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m resp = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgpt-4o-mini\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtype\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mjson_object\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# ← JSON mode\u001b[39;49;00m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msystem\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mReturn valid JSON only.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mRespond with \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\\"\u001b[39;49;00m\u001b[33;43mok\u001b[39;49m\u001b[38;5;130;43;01m\\\"\u001b[39;49;00m\u001b[33;43m: true}\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\n\u001b[32m     15\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[38;5;28mprint\u001b[39m(json.loads(resp.choices[\u001b[32m0\u001b[39m].message.content))\n",
            "\u001b[36mFile \u001b[39m\u001b[32me:\\Projects\\Semantic_models_for-MSE\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py:287\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    285\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    286\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m287\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32me:\\Projects\\Semantic_models_for-MSE\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py:1147\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   1101\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m   1102\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m   1103\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1144\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m   1145\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m   1146\u001b[39m     validate_response_format(response_format)\n\u001b[32m-> \u001b[39m\u001b[32m1147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1148\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1149\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1150\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m   1151\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1152\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1153\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1154\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1155\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1156\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1157\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1158\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1159\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1160\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1161\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1162\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1163\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1164\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1165\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1166\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1167\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_key\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1168\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1169\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1170\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msafety_identifier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1171\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1172\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1173\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1174\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1175\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1176\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1177\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1178\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1179\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1180\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1181\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mverbosity\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1184\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1185\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1186\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[32m   1187\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m   1188\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1189\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1190\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1191\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m   1192\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1193\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1194\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1195\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1196\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32me:\\Projects\\Semantic_models_for-MSE\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1259\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1245\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1247\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1254\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1255\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1256\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1257\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1258\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1259\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32me:\\Projects\\Semantic_models_for-MSE\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1047\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1044\u001b[39m             err.response.read()\n\u001b[32m   1046\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1047\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1051\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
            "\u001b[31mRateLimitError\u001b[39m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
          ]
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "import os, json\n",
        "\n",
        "assert os.getenv(\"OPENAI_API_KEY\"), \"API key missing\"\n",
        "client = OpenAI()\n",
        "\n",
        "resp = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    response_format={\"type\": \"json_object\"},   # ← JSON mode\n",
        "    messages=[\n",
        "        {\"role\":\"system\",\"content\":\"Return valid JSON only.\"},\n",
        "        {\"role\":\"user\",\"content\":\"Respond with {\\\"ok\\\": true}\"}\n",
        "    ],\n",
        "    temperature=0\n",
        ")\n",
        "print(json.loads(resp.choices[0].message.content))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
